<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 算法 | Yebangyu's Blog]]></title>
  <link href="http://www.yebangyu.org/blog/categories/suan-fa/atom.xml" rel="self"/>
  <link href="http://www.yebangyu.org/"/>
  <updated>2018-04-06T21:39:59+08:00</updated>
  <id>http://www.yebangyu.org/</id>
  <author>
    <name><![CDATA[Yebangyu]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[深入解析快速排序(Quick Sort)]]></title>
    <link href="http://www.yebangyu.org/blog/2016/03/09/quicksort/"/>
    <updated>2016-03-09T22:34:14+08:00</updated>
    <id>http://www.yebangyu.org/blog/2016/03/09/quicksort</id>
    <content type="html"><![CDATA[<p>本文将对快速排序进行深入的分析和介绍。通过学习本文，您将</p>

<blockquote>
  <ul>
    <li>秒杀快速排序面试</li>
    <li>掌握高效实现快排</li>
    <li>加深范型编程意识</li>
  </ul>
</blockquote>

<h2 id="section">八卦花絮</h2>

<p>快速排序是由图灵奖获得者、计算机语言设计大佬C. A. R. Hoare在他26岁时提出的。说起C. A. R. Hoare老爷爷，可能很多人的第一印象就是快速排序，但是快排仅仅是他人生中非常小的成就而已。例如，他在1978年提出的Communicating Sequential Processes(CSP)理论，则深深的影响了并行程序设计，Go语言中的Goroutine就是这种典范。</p>

<!--more-->

<h2 id="section-1">基本思想</h2>

<p>快速排序的思想非常简单：对于一个数组S，我们选择一个元素，称为pivot。将数组S中小于等于pivot的元素放在S的左边，大于等于pivot的元素放在S的右边。左右两部分分别记为S1和S2，然后我们递归的按上述方式对S1、S2进行排序。</p>

<p>具体说来，我们维护两个指针，采用两边扫描。从左到右扫描，当遇到一个元素大于等于pivot时，暂停。从右到左扫描，当遇到一个小于等于pivot元素时，暂停。然后交换这两个元素。继续扫描，直到两个指针相遇或者交叉。</p>

<p>从直观上看，每次递归处理的两个子数组S1、S2的大小最好是相等或者接近的，这样所花费的时间最少。</p>

<h2 id="section-2">实现细节</h2>

<p>说起来容易，做起来难了。要想正确实现快速排序非常不容易，很容易犯错。简单的修改就可能导致程序死循环或者结果错误。如果你一度感到很难在几分钟内实现一个正确的快速排序，说明你是正常人。那些五分钟内就能把快速排序写对的，几乎都是背代码。</p>

<p>我在实现以下代码时，就反复调试了十几分钟。而且，我会告诉你曾经JDK的某个版本实现中都存在bug么？</p>

<p>在给出完整代码之前，我们来考虑几个非常重要的问题。</p>

<h3 id="pivot">如何选择pivot？</h3>

<p>至少有几种显而易见的方法：</p>

<p>尝试1:选择数组中的第一个元素。成本低，但是当输入数组已经有序时，将导致O($n^2$)的复杂度。例如S={1,2,3,4,5,6,7,8,9}，如果选择第一个元素也就是1作为pivot，那么S1={1}, S2={2,3,4,5,6,7,8,9}，两个子数组非常的不平衡。当递归对S2排序时，选择2也就是S2中第一个元素作为pivot排序时，又会将S2分成两个极其不平衡的子数组。经过简单分析可知，此时算法复杂度为O($n^2$)。因此这不是一个理想、健壮的方法。</p>

<p>尝试2:随机选择一个。这种方法一般都能很好work，但是随机子程序可能非常昂贵，这可能拖慢整个程序。</p>

<p>尝试3:取中位数。取中位数可以保证S的两个子数组是等大小的（或者相差1），但是计算中位数可不是一个轻轻松松的活儿，将会严重拖慢算法速度。</p>

<p>尝试4:三数取中。尝试3方法太昂贵，我们可以稍微改变下：取数组第一个元素、最后一个元素、中间元素这三个元素的中位数。</p>

<h3 id="section-3">遇到相等的元素怎么办？</h3>

<p>左右扫描，如果遇到和pivot相等的元素怎么办？是暂停扫描还是继续扫描？</p>

<p>首先，两个方向采取的策略应该是一样的，也就是要么都暂停（然后交换），要么都继续扫描。否则将导致两个子数组不平衡。</p>

<p>其次，为了更好分析这个问题，我们不妨考虑所有元素都相同的情形。如果我们遇到和pivot相等的时候不停止，那么从左到右扫描时，两指针将相遇，此次过程结束。结果呢？什么都没做，却得到了两个大小极其不均衡的数组。算法时间复杂度为O($n^2$)。如果我们选择遇到相等元素时停止扫描，然后交换，那么虽然看上去交换的次数变多了，但是我们将得到大小相等（或者差1）的两个子数组。算法的时间复杂度为O($nlgn$)。</p>

<p>因此，遇到和pivot相等的元素时候我们都暂停扫描，交换元素后继续，直到指针相遇或者交叉。</p>

<h3 id="section-4">小数组怎么处理？</h3>

<p>随着不断的递归，待排序的子数组大小越来越小，所含元素越来越少。当子数组所含元素较少（比如说，20个）时，由于它们已经基本有序，我们改变策略，对它们改用插入排序。这也方便了三数取中策略的实现，否则我们在三数取中的时候还得特殊考虑子数组有0个、1个、2个元素的情形。当子数组多大时我们转换排序方法呢？这个最优值就依赖于体系结构了。为了找到你系统中它的最优值，请多测试！测试！测试！</p>

<h2 id="section-5">完整实现</h2>

<p>```c++
#define INLINE <strong>attribute</strong>((always_inline))
template<typename t="">
class MyCompareOperator
{
public:
  INLINE bool operator() (const T &amp;a, const T &amp;b) const { return a &lt; b;}
};
template&lt;typename T, typename CompareOperator, int64_t threshold = 20&gt;
class SoupenSort
{
public:
  static void sort(T *data, int64_t size);
private:
  static void sort_(T *data, int64_t left, int64_t right, const CompareOperator &amp;co);
  static void insertion_sort(T *data, int64_t left, int64_t right, const CompareOperator &amp;co);
  static const T&amp; get_pivot(T *data, int64_t left, int64_t right, const CompareOperator &amp;co);
};
template&lt;typename T, typename CompareOperator, int64_t threshold&gt;
INLINE void SoupenSort&lt;T, CompareOperator, threshold&gt;::sort(T *data, int64_t size)
{
  CompareOperator co;
  sort_(data, 0, size - 1, co);
}</typename></p>

<p>template&lt;typename T, typename CompareOperator, int64_t threshold&gt;
void SoupenSort&lt;T, CompareOperator, threshold&gt;::sort_(T *data, int64_t left, int64_t right, const CompareOperator &amp;co)
{
  if(right - left &gt; threshold) {
    const T&amp; pivot = get_pivot(data, left, right, co);
    int64_t i = left;
    int64_t j = right - 1;
    while(true) {
      do
      {
        ++i;
      }while(co(data[i], pivot));
      do
      {
        –j;
      }while(co(pivot, data[j]));
      if (i &lt; j) {
        std::swap(data[i], data[j]);
      } else {
        break;
      }
    }
    std::swap(data[i], data[right - 1]);//restore pivot
    sort_(data, left, i - 1, co);
    sort_(data, i + 1, right, co);
  } else {
    insertion_sort(data, left, right, co);
  }
}</p>

<p>template&lt;typename T, typename CompareOperator, int64_t threshold&gt;
INLINE void SoupenSort&lt;T, CompareOperator, threshold&gt;::insertion_sort(T *data, int64_t left, int64_t right, const CompareOperator &amp;co)
{
  int64_t begin = left + 1;
  int64_t end = right + 1;
  for (int64_t i = begin; i &lt; end; i++) {
    //insert data[i]. data[left to i-1] are ordered already
    int64_t j = i - 1;
    T tmp = data[i];
    while(j &gt;-1 &amp;&amp; co(tmp, data[j])) {
      data[j+1] = data[j];
      j–;
    }
    data[j+1] = tmp;
  }
}</p>

<p>template&lt;typename T, typename CompareOperator, int64_t threshold&gt;
INLINE const T&amp; SoupenSort&lt;T, CompareOperator, threshold&gt;::get_pivot(T *data, int64_t left, int64_t right, const CompareOperator &amp;co)
{
  int64_t mid = (left + right) / 2;
  if (co(data[mid], data[left])) {
    std::swap(data[mid], data[left]);
  }
  if (co(data[right], data[mid])) {
    std::swap(data[mid], data[right]);
  }
  if (co(data[mid], data[left])) {
    std::swap(data[mid], data[left]);
  }
  //Store pivot there to facilitate bound processing in sort_
  //data[right - 1] &lt;= data[right]
  std::swap(data[mid], data[right - 1]);
  return data[right - 1];
}
```
我们把以上实现的快速排序称为SoupenSort。是的，90行不到。</p>

<h2 id="section-6">测试结果</h2>

<p>测试程序已经放到了github上，可以从<a href="https://github.com/yebangyu/Soupen/blob/master/src/bad/test.cpp">这里</a>下载。</p>

<p>我们pk的对象包括STL中的sort，以及C语言里大名鼎鼎的qsort。</p>

<p>我们的平台是Ubuntu 64位系统 + gcc 4.8</p>

<p>测试结果：</p>

<p>1000W个随机打乱的32位无符号整数</p>

<p>开启O2优化（单位：秒）：</p>

<p>sort: 1.06</p>

<p>SoupenSort: 1.20</p>

<p>qsort: 2.08</p>

<p>未开启O2优化（单位：秒）：</p>

<p>sort: 3.29</p>

<p>SoupenSort: 2.93</p>

<p>qsort: 2.91</p>

<p>1000W个相同的整数</p>

<p>开启O2优化（单位：秒）：</p>

<p>sort: 0.23</p>

<p>SoupenSort: 0.27</p>

<p>qsort: 0.59</p>

<p>未开启O2优化（单位：秒）：</p>

<p>sort: 2.60</p>

<p>SoupenSort: 1.56</p>

<p>qsort: 0.76</p>

<p>什么结论？</p>

<p>没开优化，那么所需时间 qsort &lt; SoupenSort &lt; sort</p>

<p>开了优化，那么所需时间 sort &lt; SoupenSort &lt; qsort</p>

<p>为什么sort可以这么叼？据说它综合了插入排序、快速排序和堆排序。这让我想起了推荐和广告比赛里，有些队伍利用Ensemble Learning没节操地堆了几百个model。。。</p>

<h2 id="further-thinking">Further Thinking</h2>

<p>1，64行的 <code>while(j &gt;-1 &amp;&amp; co(tmp, data[j]))</code> 能否改为 <code>while(j &gt;-1 &amp;&amp; !co(data[j], tmp))</code> ？ 同理，36和40行能否作相应的改动？</p>

<p>2，30-46行能否改为：</p>

<p><code>c++
int64_t i = left + 1;
int64_t j = right - 2;
while(true) {
  while(co(data[i], pivot)) {
    ++i;
  }
  while(co(pivot, data[j])) {
    --j;
  }
  if (i &lt; j) {
    std::swap(data[i], data[j]);
  } else {
    break;
  }
}
</code></p>

<p>深入分析这样的case，将会对编写正确的快速排序的困难性有更深的体会，虽然我们已经有循环不变式这个强大的工具。</p>

<p>3，快速排序所需的栈空间是多少？能否进一步优化？</p>

<p>4，SoupenSort的时间复杂度是多少？O($n^2$)还是O($nlgn$)？如果是前者，那么，什么情况下是二次的？</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[深入解析Bloom Filter(中)]]></title>
    <link href="http://www.yebangyu.org/blog/2016/01/29/insidethebloomfilter/"/>
    <updated>2016-01-29T22:38:31+08:00</updated>
    <id>http://www.yebangyu.org/blog/2016/01/29/insidethebloomfilter</id>
    <content type="html"><![CDATA[<p>本篇将介绍：</p>

<blockquote>
  <ul>
    <li>d-left hashing</li>
    <li>d-left counting bloom filter</li>
  </ul>
</blockquote>

<p>在<a href="http://www.yebangyu.org/blog/2016/01/23/insidethebloomfilter/">上篇</a>文章，我们介绍了Standard Bloom Filter(SBF)和Counting Bloom Filter(CBF)。简单回顾下，我们大概思路和历程是：为了解决允许false positive下的membership问题，我们设计了哈希表算法，由于它所需空间巨大，我们引入bitmap方法；因为它false positive possibility太大，我们引入了SBF，它使用多个独立的、均匀分布的哈希函数。而SBF的一个缺点是不支持删除操作，为了能够删除，我们引入了CBF，然而，CBF存在一个问题。</p>

<p>什么问题呢？那就是空间利用率不高。这可以通过简单的数学计算知道大概：</p>

<p>考察某个位置，该位置的计数器counter的值$\xi$</p>

<p>$P(\xi = c) \approx \binom{mk}{c} {(\frac{1}{n})}^{c}({1-\frac{1}{n}})^{mk-c} = B(km,\frac{1}{n})$</p>

<!--more-->

<p>若二项分布B(n,p)里n很大，p很小时，二项分布的极限近似分布是泊松分布$P(\lambda=k) = \frac{\lambda^k}{k!}{e}^{-\lambda}$，其中$\lambda=np=\frac{km}{n}$，并结合$k = \frac{n}{m}ln2$，可以得到，counter的期望值为：</p>

<p>$E(\xi) = \lambda = np = ln2 \approx 0.7$</p>

<p>即大量的counter的值都是0，空间效率不高。</p>

<p>在介绍新的Bloom Filter之前，我们一起先看看什么是所谓的d-left hashing。</p>

<h3 id="d-left-hashing">d-left hashing</h3>

<p>在d-left hashing中，我们有d张哈希子表（序号分别为1,2,…d，并且假设是从左到右），每张子表都包含B个bucket，每个bucket都包含w个cell，每个cell可以存放一个元素。</p>

<p>为了插入一个元素x，我们：</p>

<p>1，首先通过一个哈希函数hf，得到x的哈希函数值value = hf(x)</p>

<p>2，通过value，得到d个位置（每个位置对应每张子表），表示为：</p>

<p>(1,$B_1$) , (2,$B_2$),… (d,$B_d$)</p>

<p>其中(i,$B_i$)表示第i张子表，Bucket的index为$B_i$。</p>

<p>那么，到底插入哪张表呢？d-left hashing选择$B_i$中负载最小（已经存放的元素最少）的位置。注意，这里说的是bucket的负载，不是子表的负载。如果有多个子表对应的位置负载都是最小，那么选择最左边（序号最小）的子表插入。</p>

<p>为了查找该元素，我们需要检查d个位置，wd个cell（元素）。</p>

<h3 id="d-left-counting-bloom-filter">d-left counting bloom filter</h3>

<p>在基于d-left hashing的CBF中，我们有d张哈希子表（序号分别为1,2,…d，并且假设是从左到右），每张子表都包含B个bucket，每个bucket都包含w个cell，每个cell可以存放一个counter和一个fingerprint。</p>

<p>为了插入一个元素x，我们：</p>

<p>1，首先通过一个哈希函数hf，得到x的哈希函数值value = hf(x)</p>

<p>2，通过value，得到d个位置（每个位置对应每张子表）和对应的fingerprint，表示为d个位置向量：</p>

<p>(1,$B_1$,$fp_1$) , (2,$B_2$,$fp_2$),… (d,$B_d$,$fp_d$)</p>

<p>其中位置向量(i,$B_i$,$fp_i$)表示第i张子表，Bucket的index为$B_i$，fingerprint为$fp_i$。</p>

<p>3，通过d-left hashing将x插入，如果插入的位置(i,$B_i$,$fp_i$)上已经有cell的fingerprint等于$fp_i$，那么只需要将它的counter++即可。</p>

<p>举个栗子，假设某时刻，我们有：</p>

<p><img src="http://7xnljs.com1.z0.glb.clouddn.com/dleftcbf1.jpg" alt="d-leftcbf1" /></p>

<p>2张子表（d=2），每张子表有6个bucket（B=6），每个bucket包括3个cell（w=3），每个cell可以存放一个counter(4位表示，最大值为16)和fingerprint（6位表示）。</p>

<p>假如我们要插入元素x，我们对它进行hash，得到两个位置向量：</p>

<p>(1, 1, 010100)和(2, 2, 010101)</p>

<p>$d_1$子表中index为1的bucket的负载，要小于$d_2$子表中index为2的bucket的负载，因此，我们选择插入$d_1$中，如下：</p>

<p><img src="http://7xnljs.com1.z0.glb.clouddn.com/dleftcbf2.jpg" alt="d-leftcbf2" /></p>

<p>如果得到的位置向量分别是(1, 1, 001100)和(2, 2, 010101)呢？那么，还是插入到$d_1$中index为1的bucket中，但是只需要将第二个cell里的counter++即可，如下图：</p>

<p><img src="http://7xnljs.com1.z0.glb.clouddn.com/dleftcbf3.jpg" alt="d-leftcbf3" /></p>

<p>看起来很完美，但是这种方案在删除时会有问题。比如说，还是刚才的例子，我们欲插入x和y。分别得到x和y的位置向量们：</p>

<p>x: (1, 1, 010100)和(2, 2, 010100)</p>

<p>y: (1, 1, 010100)和(2, 4, 010100)</p>

<p>根据d-left hashing，x被插入到$d_1$中index为1的bucket中；y被插入到$d_2$中index为4的bucket中。好，这没问题。如果现在要删除y呢？我们需要检查两个位置，$d_1$中的index为1的bucket，以及$d_2$中index为4的bucket，要删哪个？fp都是010100啊。这就出现问题。</p>

<p>什么时候会出现这种问题？当以下条件满足时：</p>

<p>1，两个元素的有公共【重合】的位置向量。位置向量相同，表示同一个子表，同一个bucket，以及相同的fingerprint。</p>

<p>2，其中一个元素被插入了公共位置向量对应的位置，另外一个元素没有。</p>

<p>3，欲删除未使用公共位置向量的元素（比如说上例中的y）</p>

<p>为了解决这个问题，作者做了两点改进：</p>

<p>I 引入d轮随机置换。</p>

<p>置换，即一一映射。假设置换为P，输入为a和b，那么将满足：</p>

<p>如果$a = b$，那么$P(a) = P(b)$</p>

<p>如果$a \neq b$ ，那么 $P(a) \neq P(b)$</p>

<p>为了插入x，我们首先通过一个哈希函数hf，计算它的哈希函数值value = hf(x)。然后，我们对value进行d轮随机置换，得到d个位置向量：</p>

<p>$P_1(value) = (1, B_1, fp_1)$</p>

<p>$P_2(value) = (2, B_2, fp_2)$</p>

<p>……</p>

<p>$P_d(value) = (d, B_d, fp_d)$</p>

<p>这里面有一个小问题：如果要插入的元素x和y不等，那么它们的置换可能相等吗？当然可能。因为x和y虽然不等，但是它们的hash value可能相等，这样它们的置换结果即位置向量可能相同。</p>

<p>别忘了，我们是对x和y的hash value进行置换，不是对x和y进行置换。</p>

<p>网上流传很广的<a href="http://blog.csdn.net/jiaomeng/article/details/1526099">这篇</a>文章的解释是错误的，小心！！！</p>

<p>II 插入修正</p>

<p>当得到d个位置向量后，和上面介绍的过程稍微不同：我们首先需要根据d个位置向量，从第1个子表开始，对每个子表$d_i$，去对应的位置$B_i$处查找是否有cell中的fp等于$fp_i$，如果有，我们把相应的counter++，插入动作完成，不用再继续检查后续子表了。</p>

<p>否则，当所有d个子表都没有对应的$fp_i$时，我们运用d-left hashing，插入x。</p>

<p>综合运用这两点，我们知道上面所说的删除时的问题已经不存在了。</p>

<p>假如欲插入x和y，分别对它们的hash value进行d轮（这里d=2）随机置换后，有没有可能得到如下的位置向量？</p>

<p>x: (1, 1, 010100)和(2, 2, 010101)</p>

<p>y: (1, 1, 010100)和(2, 4, 010111)</p>

<p>不可能。</p>

<p>注意到，x和y的第一个位置向量（对应第一张子表）完全相同（bucket index相同，fp也相同），也就是</p>

<p>$P_1(hf(x)) = P_1(hf(y))$</p>

<p>那么可以推出hf(x) = hf(y)，也就是x和y的哈希函数值相等，那么对于任何的i都有$P_i(hf(x)) = P_i(hf(y))$。</p>

<p>因此：</p>

<p>如果$hf(x) = hf(y)$，那么$P_i(hf(x)) = P_i(hf(y))$ (i=1,2,3…d)，假如先插入x后插入y，插入y的时候，会更新counter。后续删除x或者y都不存在上述问题。</p>

<p>如果$hf(x) \neq hf(y)$，那么$P_i(hf(x)) \neq P_i(hf(y))$ (i=1,2,3…d)，那么x和y没有公共的位置向量。后续删除x或者y都不存在上述问题。</p>

<h2 id="section">附录</h2>

<h3 id="section-1">如何随机置换</h3>

<p>作者提供了一个简单的函数：</p>

<p>$P_i(value) = (a * value ) mod 2^B$</p>

<p>其中value的范围是[0, $2^B$]，a是随机的一个奇数。</p>

<h3 id="section-2">数学分析</h3>

<p>首先，如果z是false positive，那么它的哈希函数值会和集合S中的某个元素的哈希函数值相等。也就是</p>

<p>hf(z) = hf(e) 其中 $e\in S$</p>

<p>这是因为，如果z是false positive，那么</p>

<p>$p_i(hf(z)) = p_i(hf(e))$</p>

<p>根据置换的性质，可得hf(z) = hf(e)</p>

<p>因此，false positive possibility为</p>

<p>$P = 1 - (1 - \frac{1}{B}*\frac{1}{2^r})^m$</p>

<p>根据伯努利公式，当x很小时，$(1+x)^a \approx 1 + ax$，所以</p>

<p>$P \approx 1 - (1 - m * \frac{1}{B} * \frac{1}{2^r}) \approx \frac{m}{B*2^r}$</p>

<p>那么d-left CBF的false positive和空间利用情况如何？我们下面简单分析一下：</p>

<p>比较嘛，肯定是相同的空间利用，比较谁的false positive possibility小；相同的false positive possibility下，谁所需空间少。</p>

<p>在CBF中，假设counter需要c位（<a href="http://www.yebangyu.org/blog/2016/01/23/insidethebloomfilter/">上次</a>我们分析过，c取4足矣），那么所需的空间是cn。结合$k = \frac{n}{m}ln2$，false positive possibility大约为$(0.6185)^{\frac{n}{m}}$。</p>

<p>在d-left CBF中，我们选择d=4，B=$\frac{m}{24}$，w=8（平均负载为6，这样$4 * \frac{m}{24} * 6 = m$），counter占用2位，fingerprint占用r位。那么它的空间占用为</p>

<p>$4 * \frac{m}{24} * 8  * (2+r) = \frac{4m(r+2)}{3}$</p>

<p>而false positive possibility的大概为 $\frac{m}{B*2^r} = 24 * \frac{1}{2^r}$ (别忘了，B=$\frac{m}{24}$ )</p>

<p>通过计算不难发现，当空间占用相等时，d-left CBF的false positive possibility是CBF的百分之一；当false positive possibility相等时，d-left CBF所需空间是CBF的一半。</p>

<h2 id="section-3">感谢</h2>

<p>特别感谢<a href="http://www.xiaolili.net/">汪立</a>大神参与讨论。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[深入解析Bloom Filter(上)]]></title>
    <link href="http://www.yebangyu.org/blog/2016/01/23/insidethebloomfilter/"/>
    <updated>2016-01-23T13:24:49+08:00</updated>
    <id>http://www.yebangyu.org/blog/2016/01/23/insidethebloomfilter</id>
    <content type="html"><![CDATA[<p>本文将介绍：</p>

<blockquote>
  <ul>
    <li>Bloom Filter和它的变形与拓展</li>
    <li>Bloom Filter的使用场景</li>
    <li>Bloom Filter的详细数学分析</li>
  </ul>
</blockquote>

<h2 id="section">提出问题</h2>

<p>Google的爬虫每天需要抓取大量的网页。于是就有一个问题：每当爬虫分析出一个url的时候，是抓呢，还是不抓呢？如何知道这个url已经爬过了？</p>

<!--more-->

<p>这个问题，归纳抽象后可以定义为：</p>

<p>给定一个集合S（注意，这里的集合是传统意义上的集合：元素彼此不同。本文不考虑multiset），给定一个元素e，需要判断$e\in S$ 是否成立。（学术界一般称为membership问题）</p>

<h2 id="section-1">分析问题</h2>

<p>都有哪些方案可以解决这个问题？</p>

<p>一种简单的想法是把url存储在一个哈希表中，每次去表里look up下判断是否存在。假如每个url占用40B，那么10亿条url将占用大概30多GB的内存！Can this be more space efficient ?</p>

<h2 id="section-2">解决问题</h2>

<p>我们可不可以不存url本身？这样子所需空间就会大大减少了。于是我们想到一个很经典的做法：bitmap（位图）。将集合S中的url哈希到bitmap上，给定一个url，只需要将它hash，得到它在bitmap的下标，检查该位置是否为1即可。</p>

<p>这样做空间是省了，可是也产生了一个问题：由于冲突（碰撞），不是集合S中的元素也可能被哈希到值为1的位置上，导致误报。</p>

<p>给定一个元素e，如果实际上$e\notin S$ 而被判为 $e\in S$，那么我们称e是false positive（伪正例。顺便说一句，false positive等的分析在machine learning的classification任务里评价model时非常重要）。</p>

<p>如何降低false positive的概率呢？Bloom Filter的想法是使用多个独立的哈希函数。</p>

<h3 id="standard-bloom-filter">Standard Bloom Filter</h3>

<p>在传统的Bloom Filter中，我们有：</p>

<p>集合S：其大小为m。也就是说，集合中有m个不同元素。</p>

<p>可用内存B：B被当成位数组bitmap来使用，大小为n。（有n个bit）。</p>

<p>哈希函数：有k个独立的、均匀分布的哈希函数。</p>

<p>Bloom Filter的做法是：初始时，所有比特位都初始化为0。对于集合中的每个元素，利用k个哈希函数，对它哈希得到k个位置，将bitmap中的对应的k个位置置为1。</p>

<p>给定一个元素e，为了判断它是否是集合中的元素，也利用该k个函数得到k个位置，检查该k个位置是否都为1，如果是，认为$e\in S$，否则认为$e\notin S$。</p>

<p>不难看出，如果$e\in S$，那么Bloom Filter肯定会正确判断出$e\in S$，但是它还是可能产生false positive。那么，如何分析false positive的概率呢？</p>

<p>false positive发生时，表示哈希该元素后得到的k个位置都为1。这个概率大概为：</p>

<p>$P\approx p_1^k$</p>

<p>其中$p_1$代表某位为1的概率，它等于：</p>

<p>$p_1 = 1 - p_0$</p>

<p>对于$p_0$，表示某个特定的比特位为0。什么时候该位才为0呢？也就是说m个元素各自经过k次哈希得到km个对象，没有一个对象定位到了该位置。某个对象定位到该位置的概率为$\frac{1}{n}$，因此我们可以得到：</p>

<p>$p_0 = (1 - \frac{1}{n})^{mk}$</p>

<p>分析$p_0$。在实际应用中，n一般很大，根据重要极限公式，我们有：</p>

<p>$p_0 = (1 - \frac{1}{n})^{mk} = (1-\frac{1}{n})^{-n{\frac{mk}{-n}}} \approx e^{-\frac{mk}{n}} $</p>

<p>代入到最上面的那个式子，我们不难得到：</p>

<p>$P \approx ({1 - e^{-\frac{mk}{n}}})^{k}$</p>

<p>当k为何值时，P取得最小，false positive possibility最低呢？</p>

<p>令 $f(k) = ({1 - e^{-\frac{mk}{n}}})^{k}$</p>

<p>$ln(f(k)) = kln({1 - e^{-\frac{mk}{n}}})$</p>

<p>$\frac{f\prime(k)}{f(k)} = ln({1 - e^{-\frac{mk}{n}}}) + k(\frac{1}{1 - e^{- \frac{mk}{n}}})(- e^{-\frac{mk}{n}})(\frac{-m}{n})$</p>

<p>$f\prime(k) = f(k)(ln({1 - e^{-\frac{mk}{n}}}) + k(\frac{1}{1 - e^{- \frac{mk}{n}}})(- e^{-\frac{mk}{n}})(\frac{-m}{n}))$</p>

<p>看起来够复杂了，然而别怕！！！</p>

<p>令$f\prime(k) = 0$ ， 我们有(注意到$f(k) &gt; 0$ 恒成立)：</p>

<p>$ln({1 - e^{-\frac{mk}{n}}}) + k(\frac{1}{1 - e^{- \frac{mk}{n}}})(- e^{- \frac{mk}{n}})(\frac{-m}{n}) = 0$</p>

<p>作代换，令$\lambda = e^{-\frac{mk}{n}}$ 则 $k = \frac{-nln\lambda}{m}$，代入上式，得到</p>

<p>$(1-\lambda)ln(1-\lambda) = \lambda ln\lambda$</p>

<p>因此$\lambda = \frac{1}{2}$ ， $k = \frac{n}{m}ln2$</p>

<p>也就是说，当n和m固定时，选择$k = \frac{n}{m}ln2$ 附近的一个整数，将使false positive possibility最小。</p>

<p>工程实现时，我们需要k个哈希函数或者哈希函数值。如何构造和获得k个独立的哈希函数呢？这篇<a href="https://www.eecs.harvard.edu/~michaelm/postscripts/rsa2008.pdf">论文</a> 提出，只需要两个独立的哈希函数hf1和hf2即可，也就是通过如下方式获得k个哈希函数值：</p>

<p>hash value = hf1(key) + i*hf2(key)</p>

<p>其中i=0、1、2…k-1</p>

<h3 id="counting-bloom-filter">Counting Bloom Filter</h3>

<p>除了存在false positive这个问题之外，传统的Bloom Filter还有一个不足：无法支持删除操作（想想看，是不是这样的）。而Counting Bloom Filter(CBF)就是用来解决这个问题的。</p>

<p>在CBF中，维护的不是单纯的标示0或者1的比特位，而是计数器counter。对于集合中的每个元素，利用k个哈希函数，对它哈希得到k个位置，将对应的k个位置上的k个counter都加1。删除时，只需要把k个counter都减1即可。</p>

<p>那么，这个counter应该占用几位呢？分配太多，浪费空间；分配太少，容易溢出。通过下面的分析，我们可以知道，实际使用时，4位足矣。</p>

<p>考察（是考察，不是考查。这两个词有什么区别？）某个位置，该位置的计数器counter的值$\xi$</p>

<p>$P(\xi = c) \approx \binom{mk}{c} {(\frac{1}{n})}^{c}({1-\frac{1}{n}})^{mk-c} = B(km,\frac{1}{n})$</p>

<p>这个式子有点点复杂，然而回忆下概率论里的知识：若二项分布B(n,p)里n很大，p很小时，二项分布的极限近似分布是泊松分布$P(\lambda=k) = \frac{\lambda^k}{k!}{e}^{-\lambda}$，其中$\lambda=np$，因此：</p>

<p>$P(\xi = c) \approx \binom{mk}{c} {(\frac{1}{n})}^{c}({1-\frac{1}{n}})^{mk-c} \approx \frac{({\frac{km}{n}})^{c}}{c!}{e}^{-{\frac{km}{n}}}$</p>

<p>令$k = \frac{n}{m}ln2$，代入，我们得到</p>

<p>$P(\xi &gt;16) \approx \frac{(ln2)^{16}}{16!} * \frac{1}{2} &lt; \frac{1}{16!} = \frac{1}{20922789888000}$</p>

<p>也就是说，选择4位来存counter在实际情况中已经足矣，发生溢出的概率极小。</p>

<h2 id="section-3">本文小结</h2>

<p>总结下，Bloom Filter可以用在什么地方，或者说，在什么场景下，你应该想到这种技术：</p>

<p>1，回答是或者不是的问题。你需要判断一个元素是否属于某个集合，仅仅这样。你不应该要求更多。如果你想获得该元素对应的value或者还有其他payload，那么bloom filter不适合你，你需要哈希表。</p>

<p>2，允许false positive。也就是说，发生false positive不应该是致命的。比如说，搜索引擎的爬虫里，如果url不是set的元素，却被bloom filter过滤了，那么顶多就是不抓它而已，没啥特别大的损失。</p>

<p>3，空间敏感。作为一种概率数据结构，Bloom Filter不存储原始数据（比如说url），这也是它为什么space efficient的本质原因。</p>

<p>有了Standard Bloom Filter和Counting Bloom Filter，似乎可以满足绝大多数需求了，然而，这里面还是有问题。什么问题？请看<a href="http://www.yebangyu.org/blog/2016/01/29/insidethebloomfilter/">下集</a>。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introduction To Cuckoo Hashing]]></title>
    <link href="http://www.yebangyu.org/blog/2015/12/19/cuckoo-hashing/"/>
    <updated>2015-12-19T00:41:37+08:00</updated>
    <id>http://www.yebangyu.org/blog/2015/12/19/cuckoo-hashing</id>
    <content type="html"><![CDATA[<h2 id="motivation--intuition">Motivation &amp; Intuition</h2>

<p>为什么引入<strong>Cuckoo Hashing</strong>？</p>

<p>常见的<strong>hashing</strong>处理冲突方法一般包括两种：<strong>Separate Chaining</strong>和<strong>Open Addressing</strong>（<strong>Linear Probing</strong>）。<strong>Separate Chaining</strong>是将冲突的元素组织成一个链表（其实组织成一个二叉搜索树也是完全没问题的，甚至跳表也行），<strong>Open Addressing</strong>将冲突的元素还是放在哈希表<strong>slot</strong>中，使用线性探测等方法进行处理。</p>

<p>那么，这两种方法，都有啥优缺点呢？</p>

<!--more-->

<p><strong>Separate Chaining</strong> : 实现简单，但是对<strong>cache</strong>不友好，<strong>cache miss rate</strong>较高。</p>

<p><strong>Open Addressing</strong> : 实现相对复杂一点点，对<strong>cache</strong>很友好，但是对<strong>load factor</strong>要求苛刻：<strong>load factor</strong>稍高性能就急剧下降。</p>

<p>这两种方式下，查找某个元素的最坏时间都是<strong>O(n)</strong>。</p>

<p>你说，<strong>OK，OK</strong>，我知道，这些都是常识。那么，是否可以做到查找最坏是<strong>O(1)</strong>呢？</p>

<p>一种思路是元素只可能被安置到有限的常数(记为<strong>K</strong>)个位置，插入时，如果发生冲突，由于每个元素可以存放的位置有<strong>K</strong>个，因此可以对表部分元素进行重排，产生一个空缺的位置。</p>

<p><strong>Cuckoo Hashing</strong>就是这样的方式。当<strong>K=2</strong>时，<strong>Cuckoo Hashing</strong>在<strong>load factor</strong>为<strong>50%</strong>左右的情况下表现较佳。如果<strong>K=4</strong>，那么甚至可以在<strong>97%</strong>的<strong>load factor</strong>下良好工作。</p>

<h2 id="cuckoo-hashing">Cuckoo Hashing</h2>

<p>一般的<strong>Hashing</strong>只包括一个<strong>Hash Tables</strong>，但是<strong>Cuckoo Hashing</strong>由两张甚至多张表构成。每张表对应一个哈希函数。本文讨论两张哈希表（记为<strong>table1</strong>和<strong>table2</strong>）、两个哈希函数（记为<strong>hf1</strong>和<strong>hf2</strong>）这种常见情形。</p>

<h3 id="insert">Insert</h3>

<p>首先通过<strong>hf1</strong>计算出一个<strong>slot index</strong>，然后查看<strong>table1</strong>中该<strong>slot</strong>是否<strong>vacant</strong>，如果是，则插入；否则通过<strong>hf2</strong>计算出一个<strong>slot index</strong>，通过查看<strong>table2</strong>中该<strong>slot</strong>是否<strong>vacant</strong>，如果是，则插入，否则执行<strong>rearrange</strong>操作。</p>

<p><strong>rearrange</strong>操作的过程：随机选出一张表，将<strong>slot index</strong>对应的那个元素踢出(<strong>evict</strong>)，把我们待插入的元素插到那个位置。那被踢出来的元素呢？尝试插入到另外一张表对应的<strong>slot</strong>处，这时候可能又踢出一个元素，接下去就是递归的执行这个过程，直到所有元素都安置妥当。</p>

<p>举个例子吧，假如某个时刻，两个哈希表的内容如下：</p>

<p><img src="http://7xnljs.com1.z0.glb.clouddn.com/table1.jpg" alt="table1" /></p>

<p>假设我们待插入的元素为<strong>77</strong>。</p>

<p><strong>slot index1 = hf1(77) = 1</strong></p>

<p><strong>Table1</strong>中的<strong>index</strong>为<strong>1</strong>的<strong>slot</strong>已经被<strong>78</strong>占了。那么看<strong>Table2</strong>：</p>

<p><strong>slot index2 = hf2(77) = 3</strong></p>

<p><strong>Table2</strong>中的<strong>index</strong>为<strong>3</strong>的<strong>slot</strong>已经被<strong>33</strong>占了。因此执行<strong>rearrange</strong>。</p>

<p>执行<strong>rearrange</strong>动作，选择<strong>Table2</strong>，将<strong>slot index = 3</strong>的元素<strong>33</strong>踢出，插入<strong>77</strong>。然后被踢出的元素<strong>33</strong>，计算它在<strong>Table1</strong>中的<strong>index</strong>为<strong>slot index1 = hf2(33) = 2</strong>，因此将<strong>95</strong>踢出，插入<strong>33</strong>。被踢出的元素<strong>95</strong>在<strong>Table2</strong>中的<strong>slot index</strong>为<strong>2</strong>，该<strong>slot</strong>为<strong>vacant</strong>，没人使用，因此将<strong>95</strong>插入。完毕。现在的<strong>Tables</strong>中元素为：</p>

<p><img src="http://7xnljs.com1.z0.glb.clouddn.com/table2.jpg" alt="table2" /></p>

<p>值得注意的是，<strong>rearrange</strong>可能失败（表满了;或者发生“死循环”），此时需要进行<strong>rehash</strong>，因此代码里需要有一定的判断。当<strong>K=2</strong>时，只要<strong>load factor</strong>低于<strong>50%</strong>，需要<strong>rehash</strong>的概率很小很小。</p>

<p>在某些假设下，插入操作的摊还期望复杂度为常数时间。</p>

<h3 id="find">Find</h3>

<p>要检查的<strong>slot</strong>一共两个，<strong>index</strong>分别为<strong>hf1(key)</strong>和<strong>hf2(key)</strong>，因此只要查看一下<strong>Table1</strong>中的<strong>hf1(key)</strong>以及<strong>Table2</strong>中的<strong>hf2(key)</strong>这两个<strong>slot</strong>即可。时间复杂度为<strong>O(1)</strong>。</p>

<h3 id="del">Del</h3>

<p>同<strong>Find</strong>，要检查的<strong>slot</strong>也就两个，复杂度为<strong>O(1)</strong>。</p>

<h2 id="section">实现</h2>

<p>实现了Bucketized Cuckoo Hashmap，有需要的可以参考<a href="https://github.com/yebangyu/Soupen/blob/master/src/ds/soupen_cuckoo_hashmap.h">这里</a></p>

<h2 id="section-1">其他</h2>

<p>1，我们注意到，<strong>Cuckoo Hashing</strong>的精髓是使用两个不同的哈希函数，而不是两张表。两张表的存在，仅仅是为了分析上的方便。</p>

<p>当需要<strong>rehash</strong>而<strong>load factor</strong>又没达到<strong>100%</strong>时，我们其实不需要扩容哈希表，只需要更换哈希函数。</p>

<p>2，为嘛叫做<strong>Cuckoo Hashing</strong>？<strong>Cuckoo</strong>，即杜鹃鸟（布谷鸟），这种鸟有一种尿性：孵卵寄生。把蛋产到别的鸟窝里，让别人帮它孵化。这还不算，还要把人家寄主的一些卵给移走（不然容易引起怀疑嘛，毕竟鸟窝里突然多出几枚蛋。至于移走多少，就得看杜鹃鸟数学合不合格了）！等卵孵化完成，幼雏会将鸟窝里寄主的卵和其他幼雏推出鸟窝。真是牛逼闪闪了。</p>

<h2 id="section-2">参考文献</h2>

<p>http://resources.mpi-inf.mpg.de/departments/d1/teaching/ws14/AlgoDat/materials/cuckoo.pdf</p>

<p><strong>Cuckoo Hashing</strong>原始论文</p>

<p>https://www.eecs.harvard.edu/~michaelm/postscripts/esa2009.pdf</p>

<p>这篇文章介绍了一些关于<strong>Cuckoo Hashing</strong>的<strong>Open Questions</strong></p>

<p>http://web.stanford.edu/class/cs166/lectures/13/Slides13.pdf</p>

<p>这个<strong>slides</strong>偏重对<strong>Cuckoo Hashing</strong>理论上的分析，注意其中对于插入操作的处理和本文介绍的不同。</p>

<p>http://excess-project.eu/publications/published/CuckooHashing_ICDCS.pdf</p>

<p>碉堡了，<strong>Lock Free Cuckoo Hashing</strong>。</p>
]]></content>
  </entry>
  
</feed>
